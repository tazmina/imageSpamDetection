{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import glob, os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "from skimage import feature\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from IPython.display import SVG, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Constants\n",
    "IMG_WIDTH = 32\n",
    "IMG_HEIGHT = 32\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    INPUT_SHAPE = (3, IMG_WIDTH * 2, IMG_HEIGHT)\n",
    "else:\n",
    "    INPUT_SHAPE = (IMG_WIDTH * 2, IMG_HEIGHT, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All image processing and plot related\n",
    "\n",
    "def plotImage(image):\n",
    "    cv_rgb2 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(cv_rgb2)\n",
    "    plt.show()\n",
    "\n",
    "def plotImageFromPath(imagePath):\n",
    "    plotImage(cv2.imread(imagePath))\n",
    "\n",
    "def shape_cannyEdgesOld(cv2Image, cannyImagePath):\n",
    "    v = numpy.median(cv2Image)\n",
    "    sigma = 0.0\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    #print \"Lower\", lower, \"Upper\", upper\n",
    "    grayScaleImage = cv2.cvtColor(cv2Image, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(grayScaleImage, 10, 255)\n",
    "    cv2.imshow('Canny edges',edges)\n",
    "    cv2.imwrite(cannyImagePath, edges)\n",
    "\n",
    "def shape_cannyEdges(cv2Image, cannyImagePath):\n",
    "    cv2Image[0,0] = (255, 0, 0)\n",
    "    cv2Image[0,1] = (0, 255, 0)\n",
    "    cv2Image[0,2] = (0, 0, 255)\n",
    "    \n",
    "    v = numpy.median(cv2Image)\n",
    "    sigma = 0.0\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    #print \"Lower\", lower, \"Upper\", upper\n",
    "    grayScaleImage = cv2.cvtColor(cv2Image, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(grayScaleImage, 10, 255)\n",
    "    cv2.imshow('Canny edges',edges)\n",
    "    cv2.imwrite(cannyImagePath, edges)\n",
    "    \n",
    "def shape_hog(cv2Image, fileName): \n",
    "    grayScaleImage = cv2.cvtColor(cv2Image, cv2.COLOR_BGR2GRAY)\n",
    "    fd, hog_image = feature.hog(grayScaleImage, orientations=8, pixels_per_cell=(16, 16),cells_per_block=(1, 1), visualise=True)\n",
    "    \n",
    "    cv2.imshow('HOG',hog_image)\n",
    "    cv2.imwrite(fileName, hog_image)\n",
    "    \n",
    "def create_canny_edge_image(origImageDir, origImageName):\n",
    "    \n",
    "    origImagePath = origImageDir + '/' + origImageName\n",
    "    print(origImagePath)\n",
    "    \n",
    "    cannyImageName = \"canny_\" + origImageName\n",
    "    cannyImagePath = origImageDir + '/' + cannyImageName\n",
    "    plainImage = cv2.imread(origImagePath)\n",
    "    shape_cannyEdges(plainImage, cannyImagePath)\n",
    "    \n",
    "    return cannyImagePath\n",
    "    \n",
    "def create_canny_for_all_img(origImageDir):\n",
    "    imgFiles = [filename for filename in os.listdir(origImageDir)\n",
    "                if (not filename.startswith(\"canny\") and filename.endswith(\".jpg\") )]\n",
    "    for origImageName in imgFiles:\n",
    "        cannyImageName = \"canny_\" + origImageName\n",
    "        cannyImagePath = origImageDir + '/' + cannyImageName\n",
    "        \n",
    "        if not os.path.exists(cannyImagePath):\n",
    "            create_canny_edge_image(origImageDir, origImageName)\n",
    "            \n",
    "def create_color_histogram (origImageDir, origImageName):\n",
    "    origImagePath = origImageDir + '/' + origImageName\n",
    "    plainImage = cv2.imread(origImagePath)\n",
    "    \n",
    "    hist = cv2.calcHist([plainImage], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    hist = hist.flatten()\n",
    "    print (hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All image feature verctor related\n",
    "\n",
    "def create_features_for_all_raw_img(origImageDir, isSpam):\n",
    "    imgFiles = [filename for filename in os.listdir(origImageDir)\n",
    "                if ((not filename.startswith(\"canny\")) and filename.endswith(\".jpg\") )]\n",
    "\n",
    "    res = [create_feature_vector(origImageDir, origImageName, isSpam) for origImageName in imgFiles]\n",
    "    return numpy.array(res)\n",
    "            \n",
    "def create_features_for_all_canny_img(origImageDir, isSpam):\n",
    "    imgFiles = [filename for filename in os.listdir(origImageDir)\n",
    "                if (filename.startswith(\"canny\") and filename.endswith(\".jpg\") )]\n",
    "    res = [create_feature_vector(origImageDir, origImageName, isSpam) for origImageName in imgFiles]\n",
    "    return numpy.array(res)\n",
    "    \n",
    "def create_feature_vector(origImageDir, origImageName, isSpam, numRow=IMG_HEIGHT, numCol=IMG_WIDTH):\n",
    "    origImagePath = origImageDir + '/' + origImageName\n",
    "    plainImage = cv2.imread(origImagePath)\n",
    "    resizedImage = cv2.resize(plainImage, (numRow, numCol))\n",
    "    h = resizedImage.shape[0]\n",
    "    w = resizedImage.shape[1]\n",
    "    res = numpy.ndarray(shape=(3, h, w), dtype=float, order='F')\n",
    "    # loop over the image, pixel by pixel\n",
    "    for y in range(0, h):\n",
    "        for x in range(0, w):\n",
    "            # threshold the pixel\n",
    "            color = resizedImage[y,x] \n",
    "            res[0, y, x] = color[0] / 255.0\n",
    "            res[1, y, x] = color[1] / 255.0\n",
    "            res[2, y, x] = color[2] / 255.0\n",
    "    return numpy.append(res.flatten(), isSpam)\n",
    "        \n",
    "def get_feature_with_labels(howMany=None, nonSpamDir=\"NaturalImages\", spamDir=\"SpamImages\"):\n",
    "    create_canny_for_all_img(nonSpamDir)\n",
    "    data_nonSpam_raw = create_features_for_all_raw_img(nonSpamDir, 0)\n",
    "    data_nonSpam_canny = create_features_for_all_canny_img(nonSpamDir, 0)\n",
    "    data_nonSpam = numpy.column_stack((data_nonSpam_raw[:,:-1], data_nonSpam_canny))\n",
    "\n",
    "    create_canny_for_all_img(spamDir)\n",
    "    data_Spam_raw = create_features_for_all_raw_img(spamDir, 1)\n",
    "    data_Spam_canny = create_features_for_all_canny_img(spamDir, 1)\n",
    "    data_Spam = numpy.column_stack((data_Spam_raw[:,:-1], data_Spam_canny))\n",
    "    \n",
    "    data = numpy.concatenate((data_nonSpam, data_Spam), axis=0)\n",
    "    numpy.random.shuffle(data)\n",
    "\n",
    "    print(\"data_nonSpam, using directory:\", nonSpamDir)\n",
    "    print(data_nonSpam)\n",
    "    print(\"data_Spam, using directory:\", spamDir)\n",
    "    print(data_Spam)\n",
    "    print(\"data\")\n",
    "    print(data)\n",
    "\n",
    "    if howMany is not None:\n",
    "        data = data[0:howMany]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_nonSpam, using directory: NaturalImages\n",
      "[[0.         0.         0.00392157 ... 0.         0.17254902 0.        ]\n",
      " [0.18039216 0.56078431 0.27843137 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.25490196 0.27058824 0.28627451 ... 0.         0.         0.        ]\n",
      " [0.1372549  0.14509804 0.14509804 ... 0.         0.         0.        ]\n",
      " [0.37647059 0.83529412 0.89411765 ... 0.         0.         0.        ]]\n",
      "data_Spam, using directory: SpamImages\n",
      "[[0.07058824 0.78431373 0.0745098  ... 0.         0.         1.        ]\n",
      " [0.95686275 0.94509804 0.94509804 ... 0.         0.         1.        ]\n",
      " [1.         1.         1.         ... 0.         0.         1.        ]\n",
      " ...\n",
      " [0.76470588 0.76078431 0.78431373 ... 0.         0.         1.        ]\n",
      " [1.         1.         1.         ... 0.         0.         1.        ]\n",
      " [0.83921569 0.98823529 0.95294118 ... 0.         0.         1.        ]]\n",
      "data\n",
      "[[0.96862745 0.96078431 0.50588235 ... 0.00392157 0.00784314 1.        ]\n",
      " [0.98431373 0.98431373 0.98431373 ... 0.         0.         1.        ]\n",
      " [0.         0.         0.01176471 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.36470588 0.69411765 0.81176471 ... 0.25098039 0.01960784 0.        ]\n",
      " [0.05098039 0.04313725 0.04313725 ... 0.         0.         0.        ]\n",
      " [0.67058824 0.9372549  0.32941176 ... 0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# For testing, uncomment and save data to reuse\n",
    "data = get_feature_with_labels(nonSpamDir=\"NaturalImages\", spamDir=\"SpamImages\")\n",
    "#data = get_feature_with_labels(nonSpamDir=\"ChallengeHam1\", spamDir=\"ChallengeSpam1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot related\n",
    "def draw_accuracy_and_loss(history):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def draw_roc(y_predicted, y_actual):\n",
    "    fpr, tpr, thresholds = roc_curve(y_predicted, y_actual)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_keras_model(model, show_shapes=True, show_layer_names=True):\n",
    "    model_svg = model_to_dot(model, show_shapes=show_shapes, show_layer_names=show_layer_names).create(prog='dot',format='svg')\n",
    "    display(SVG(model_svg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learning algorithm related\n",
    "\n",
    "# Feed forward\n",
    "def run_feed_forward(data, do_plot=False):\n",
    "    \n",
    "    INPUT_DIMENSION = len(data[0]) - 1\n",
    "    LAYER_1_DIMENSION = 300\n",
    "    LAYER_2_DIMENSION = 300\n",
    "    OUTPUT_DIMENSION = 1\n",
    "    EPOCH = 100\n",
    "    \n",
    "    train_len = int(len(data) * .7)\n",
    "    data_train = data[0:train_len]\n",
    "    data_test = data[train_len:]\n",
    "\n",
    "    num_col = len(data_train[0]) - 1\n",
    "\n",
    "    x_train = data_train[:, 0:num_col]\n",
    "    y_train = data_train[:, num_col:].flatten()\n",
    "\n",
    "    x_test = data_test[:, 0:num_col]\n",
    "    y_test = data_test[:, num_col:].flatten()\n",
    "    \n",
    "    # Early stopping  \n",
    "    early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(LAYER_1_DIMENSION,\n",
    "                    input_dim=INPUT_DIMENSION,\n",
    "                    activation='relu'))\n",
    "    # With regularizers\n",
    "    #model.add(Dense(LAYER_1_DIMENSION,\n",
    "    #                input_dim=INPUT_DIMENSION,\n",
    "    #                activation='relu',\n",
    "    #                kernel_regularizer=regularizers.l2(0.01),\n",
    "    #                activity_regularizer=regularizers.l1(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(LAYER_2_DIMENSION,\n",
    "                    activation='relu'))\n",
    "    # With regularizers\n",
    "    #model.add(Dense(LAYER_2_DIMENSION,\n",
    "    #                activation='relu',\n",
    "    #                kernel_regularizer=regularizers.l2(0.01),\n",
    "    #                activity_regularizer=regularizers.l1(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(OUTPUT_DIMENSION, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(x_train,\n",
    "                        y_train,\n",
    "                        epochs=EPOCH,\n",
    "                        batch_size=64,\n",
    "                        validation_split=0.33,\n",
    "                        callbacks=[early_stop])\n",
    "    \n",
    "    score = model.evaluate(x_test, y_test, batch_size=64)\n",
    "    print (score)\n",
    "    \n",
    "    if do_plot:\n",
    "        plot_keras_model(model)\n",
    "        draw_accuracy_and_loss(history)\n",
    "\n",
    "    return score\n",
    "\n",
    "# CNN\n",
    "def run_cnn(data, do_plot=False):\n",
    "    EPOCH = 100\n",
    "    \n",
    "    train_len = int(len(data) * .7)\n",
    "    data_train = data[0:train_len]\n",
    "    data_test = data[train_len:]\n",
    "\n",
    "    num_col = len(data_train[0]) - 1\n",
    "\n",
    "    # Convert 1d array back to image for convolution\n",
    "    x_train_1D = data_train[:, 0:num_col]\n",
    "    x_train = numpy.array([z.reshape(INPUT_SHAPE) for z in x_train_1D])\n",
    "    y_train = data_train[:, num_col:].flatten()\n",
    "\n",
    "    # Convert 1d array back to image for convolution\n",
    "    x_test_1D = data_test[:, 0:num_col]\n",
    "    x_test = numpy.array([z.reshape(INPUT_SHAPE) for z in x_test_1D])\n",
    "    y_test = data_test[:, num_col:].flatten()\n",
    "    \n",
    "    # Early stopping  \n",
    "    early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=INPUT_SHAPE))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train,\n",
    "                        y_train,\n",
    "                        epochs=EPOCH,\n",
    "                        batch_size=64,\n",
    "                        validation_split=0.33,\n",
    "                        callbacks=[early_stop])\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, batch_size=64)\n",
    "    print (score)\n",
    "    \n",
    "    if do_plot:\n",
    "        plot_keras_model(model)\n",
    "        draw_accuracy_and_loss(history)\n",
    "        \n",
    "    return score\n",
    "\n",
    "# Svm\n",
    "def run_svm(data, do_plot=False):\n",
    "    \n",
    "    train_len = int(len(data) * .7)\n",
    "    data_train = data[0:train_len]\n",
    "    data_test = data[train_len:]\n",
    "    \n",
    "    num_col = len(data_train[0]) - 1\n",
    "    \n",
    "    x_train = data_train[:, 0:num_col]\n",
    "    y_train = data_train[:, num_col:].flatten()\n",
    "    \n",
    "    x_test = data_test[:, 0:num_col]\n",
    "    y_test = data_test[:, num_col:].flatten()\n",
    "    \n",
    "    clf = SVC(C=1.0, kernel='rbf')\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predicted = clf.predict(x_test)\n",
    "    score = clf.score(x_test, y_test) \n",
    "    print (score)\n",
    "    \n",
    "    if do_plot:\n",
    "        draw_roc(y_predicted, y_test)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 781 samples, validate on 386 samples\n",
      "Epoch 1/100\n",
      "781/781 [==============================] - 4s 5ms/step - loss: 0.5748 - acc: 0.7170 - val_loss: 0.4315 - val_acc: 0.7228\n",
      "Epoch 2/100\n",
      "320/781 [===========>..................] - ETA: 1s - loss: 0.4778 - acc: 0.7562"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "    \n",
    "def main():\n",
    "    # This runs the model 10 times with x number of rows\n",
    "    #numRowsToConsider = 100\n",
    "    numRowsToConsider = None\n",
    "    numIter = 1\n",
    "    sum = 0\n",
    "    for i in range(0, numIter):\n",
    "        #data = get_feature_with_labels(numRowsToConsider, nonSpamDir=\"NaturalImages\", spamDir=\"SpamImages\")\n",
    "        #sum += run_svm(data, True)\n",
    "        #sum += run_feed_forward(data, True)[1]\n",
    "        sum += run_cnn(data, True)[1]\n",
    "    sum /= numIter\n",
    "    print (sum)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section and rest are just tests\n",
    "def extract_features(imagePath, vector_size=32):\n",
    "    image = imageio.imread(imagePath)\n",
    "    alg = cv2.KAZE_create()\n",
    "    kps = alg.detect(image)\n",
    "    kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "    print (len(kps))\n",
    "    kps, dsc = alg.compute(image, kps)\n",
    "    print (len(dsc))\n",
    "    print (len(dsc[0]))\n",
    "    dsc = dsc.flatten()\n",
    "    print (len(dsc))\n",
    "    needed_size = (vector_size * 32)\n",
    "    if dsc.size < needed_size:\n",
    "        dsc = numpy.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "    return dsc\n",
    "\n",
    "def main2():\n",
    "    #features = create_feature_vector(\"SpamImages\", \"fire.jpg\")\n",
    "    #print len(features)\n",
    "    #print features\n",
    "    #image = cv2.imread(\"SpamImages/fire.jpg\")\n",
    "    #plotImage(image)\n",
    "    #image2 = cv2.resize(image, (600, 600))\n",
    "    #plotImage(image2)\n",
    "    \n",
    "    \n",
    "    \"\"\"data = get_feature_with_labels()\n",
    "    data\"\"\"\n",
    "    \n",
    "    #print (len(data[0]))\n",
    "    \n",
    "    \n",
    "\n",
    "    #create_feature_vector_for_canny(\"NaturalImages\", origImageName)\n",
    "    \n",
    "    #plainImageFileName = \"SpamImages/boots1.jpg\"\n",
    "    \"\"\"plainImage =  cv2.imread(plainImageFileName)\n",
    "    shape_hog(plainImage, \"HOG-Ham.png\")\n",
    "    \n",
    "    #plt.imshow(plainImage, cmap = 'gray', interpolation = 'bicubic')\n",
    "    #plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "    #plt.show()\n",
    "    cv_rgb = cv2.cvtColor(plainImage, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(cv_rgb)\n",
    "    plt.show()\n",
    "    \n",
    "    plainImage2 =  cv2.imread(\"HOG-Ham.png\")\n",
    "\n",
    "    print \"hi\"\n",
    "    \n",
    "    cv_rgb2 = cv2.cvtColor(plainImage2, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(cv_rgb2)\n",
    "    plt.show()\n",
    "\n",
    "    shape_cannyEdges(plainImage)\n",
    "    cv_rgb2 = cv2.cvtColor(cv2.imread(\"Cannyedges.jpg\"), cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(cv_rgb2)\n",
    "    plt.show()\"\"\"\n",
    "    \n",
    "    #x = create_feature_vector_for_canny(\"SpamImages\", \"fire.jpg\", 3.0)\n",
    "    numpy.set_printoptions(threshold=100)\n",
    "    #print x\n",
    "    \n",
    "    x = numpy.ndarray((10, 3))\n",
    "    print(x)\n",
    "    train_len = int(len(x) * .7)\n",
    "    #print x[0:train_len]\n",
    "    #print \"sep\"\n",
    "    #print x[train_len:]\n",
    "    \n",
    "    num_col = len(x[0]) - 1\n",
    "    \n",
    "    print(x[:,0:num_col])\n",
    "    \n",
    "    print(x[:, num_col:].flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
