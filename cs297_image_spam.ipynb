{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# All imports\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import glob, os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import sys\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "from skimage import feature\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from IPython.display import SVG, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Constants\n",
    "IMG_WIDTH = 32\n",
    "IMG_HEIGHT = 32\n",
    "\n",
    "USE_RAW_IMAGE_FEATURES = True\n",
    "USE_CANNY_IMAGE_FEATURES = True\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    INPUT_SHAPE = (3, IMG_WIDTH * 2, IMG_HEIGHT)\n",
    "else:\n",
    "    INPUT_SHAPE = (IMG_WIDTH * 2, IMG_HEIGHT, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All image processing and plot related\n",
    "\n",
    "def plotImage(image):\n",
    "    cv_rgb2 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(cv_rgb2)\n",
    "    plt.show()\n",
    "\n",
    "def plotImageFromPath(imagePath):\n",
    "    plotImage(cv2.imread(imagePath))\n",
    "\n",
    "def shape_cannyEdgesOld(cv2Image, cannyImagePath):\n",
    "    v = numpy.median(cv2Image)\n",
    "    sigma = 0.0\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    #print \"Lower\", lower, \"Upper\", upper\n",
    "    grayScaleImage = cv2.cvtColor(cv2Image, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(grayScaleImage, 10, 255)\n",
    "    cv2.imshow('Canny edges',edges)\n",
    "    cv2.imwrite(cannyImagePath, edges)\n",
    "\n",
    "def shape_cannyEdges(cv2Image, cannyImagePath):\n",
    "    cv2Image[0,0] = (255, 0, 0)\n",
    "    cv2Image[0,1] = (0, 255, 0)\n",
    "    cv2Image[0,2] = (0, 0, 255)\n",
    "    \n",
    "    v = numpy.median(cv2Image)\n",
    "    sigma = 0.0\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    #print \"Lower\", lower, \"Upper\", upper\n",
    "    grayScaleImage = cv2.cvtColor(cv2Image, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(grayScaleImage, 10, 255)\n",
    "    cv2.imshow('Canny edges',edges)\n",
    "    cv2.imwrite(cannyImagePath, edges)\n",
    "    \n",
    "def shape_hog(cv2Image, fileName): \n",
    "    grayScaleImage = cv2.cvtColor(cv2Image, cv2.COLOR_BGR2GRAY)\n",
    "    fd, hog_image = feature.hog(grayScaleImage, orientations=8, pixels_per_cell=(16, 16),cells_per_block=(1, 1), visualise=True)\n",
    "    \n",
    "    cv2.imshow('HOG',hog_image)\n",
    "    cv2.imwrite(fileName, hog_image)\n",
    "    \n",
    "def create_canny_edge_image(origImageDir, origImageName):\n",
    "    \n",
    "    origImagePath = origImageDir + '/' + origImageName\n",
    "    print(origImagePath)\n",
    "    \n",
    "    cannyImageName = \"canny_\" + origImageName\n",
    "    cannyImagePath = origImageDir + '/' + cannyImageName\n",
    "    plainImage = cv2.imread(origImagePath)\n",
    "    shape_cannyEdges(plainImage, cannyImagePath)\n",
    "    \n",
    "    return cannyImagePath\n",
    "    \n",
    "def create_canny_for_all_img(origImageDir):\n",
    "    imgFiles = [filename for filename in os.listdir(origImageDir)\n",
    "                if (not filename.startswith(\"canny\") and filename.endswith(\".jpg\") )]\n",
    "    for origImageName in imgFiles:\n",
    "        cannyImageName = \"canny_\" + origImageName\n",
    "        cannyImagePath = origImageDir + '/' + cannyImageName\n",
    "        \n",
    "        if not os.path.exists(cannyImagePath):\n",
    "            create_canny_edge_image(origImageDir, origImageName)\n",
    "            \n",
    "def create_color_histogram (origImageDir, origImageName):\n",
    "    origImagePath = origImageDir + '/' + origImageName\n",
    "    plainImage = cv2.imread(origImagePath)\n",
    "    \n",
    "    hist = cv2.calcHist([plainImage], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    hist = hist.flatten()\n",
    "    print (hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All image feature verctor related\n",
    "\n",
    "def create_features_for_all_raw_img(origImageDir, isSpam):\n",
    "    imgFiles = [filename for filename in os.listdir(origImageDir)\n",
    "                if ((not filename.startswith(\"canny\")) and filename.endswith(\".jpg\") )]\n",
    "\n",
    "    res = [create_feature_vector(origImageDir, origImageName, isSpam) for origImageName in imgFiles]\n",
    "    return numpy.array(res)\n",
    "            \n",
    "def create_features_for_all_canny_img(origImageDir, isSpam):\n",
    "    imgFiles = [filename for filename in os.listdir(origImageDir)\n",
    "                if (filename.startswith(\"canny\") and filename.endswith(\".jpg\") )]\n",
    "    res = [create_feature_vector(origImageDir, origImageName, isSpam) for origImageName in imgFiles]\n",
    "    return numpy.array(res)\n",
    "    \n",
    "def create_feature_vector(origImageDir, origImageName, isSpam, numRow=IMG_HEIGHT, numCol=IMG_WIDTH):\n",
    "    origImagePath = origImageDir + '/' + origImageName\n",
    "    plainImage = cv2.imread(origImagePath)\n",
    "    resizedImage = cv2.resize(plainImage, (numRow, numCol))\n",
    "    h = resizedImage.shape[0]\n",
    "    w = resizedImage.shape[1]\n",
    "    res = numpy.ndarray(shape=(3, h, w), dtype=float, order='F')\n",
    "    # loop over the image, pixel by pixel\n",
    "    for y in range(0, h):\n",
    "        for x in range(0, w):\n",
    "            # threshold the pixel\n",
    "            color = resizedImage[y,x] \n",
    "            res[0, y, x] = color[0] / 255.0\n",
    "            res[1, y, x] = color[1] / 255.0\n",
    "            res[2, y, x] = color[2] / 255.0\n",
    "    return numpy.append(res.flatten(), isSpam)\n",
    "\n",
    "def crete_canny_and_get_features_with_labels(directory, label, use_raw_images, use_canny_images):\n",
    "    if (not use_raw_images) and (not use_canny_images):\n",
    "        raise Exception('At least use_raw_images or use_canny_images need to be set to true')\n",
    "        \n",
    "    create_canny_for_all_img(directory)\n",
    "    data_raw = create_features_for_all_raw_img(directory, label)\n",
    "    data_canny = create_features_for_all_canny_img(directory, label)\n",
    "    \n",
    "    if (use_raw_images and use_canny_images):\n",
    "        return numpy.column_stack((data_raw[:,:-1], data_canny))\n",
    "    elif use_raw_images:\n",
    "        return data_raw\n",
    "    else:\n",
    "        return data_canny\n",
    "\n",
    "def get_feature_with_labels(\n",
    "    ham_dir=\"NaturalImages\",\n",
    "    spam_dir=\"SpamImages\",\n",
    "    show=False,\n",
    "    use_raw_images=True,\n",
    "    use_canny_images=True\n",
    "):\n",
    "    data_ham = crete_canny_and_get_features_with_labels(\n",
    "        directory=ham_dir,\n",
    "        label=0,\n",
    "        use_raw_images=use_raw_images,\n",
    "        use_canny_images=use_canny_images\n",
    "    )\n",
    "    data_spam = crete_canny_and_get_features_with_labels(\n",
    "        directory=spam_dir,\n",
    "        label=1,\n",
    "        use_raw_images=use_raw_images,\n",
    "        use_canny_images=use_canny_images\n",
    "    )\n",
    "    \n",
    "    data = numpy.concatenate((data_ham, data_spam), axis=0)\n",
    "    numpy.random.shuffle(data)\n",
    "\n",
    "    if show:\n",
    "        #numpy.set_printoptions(threshold=sys.maxsize)\n",
    "        numpy.set_printoptions(threshold=10)\n",
    "        print(\"data_ham, using directory:\", ham_dir)\n",
    "        print(data_ham)\n",
    "        print(\"data_spam, using directory:\", spam_dir)\n",
    "        print(data_spam)\n",
    "        print(\"data\")\n",
    "        print(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot related\n",
    "def draw_accuracy_and_loss(history):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def draw_roc(y_predicted, y_actual):\n",
    "    fpr, tpr, thresholds = roc_curve(y_predicted, y_actual)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "def add_plot(plt, svm_res, color, label):\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(svm_res[0], svm_res[1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.plot(fpr, tpr, color=color, lw=1, label=(label + ' ROC curve (area = %0.2f)') % roc_auc)\n",
    "    \n",
    "    \n",
    "def draw_roc_for_all(svm_rbf_public, svm_linear_public, svm_rbf_cha1, svm_linear_cha1, svm_rbf_cha2, svm_linear_cha2):\n",
    "    plt.figure()\n",
    "    \n",
    "    #fpr, tpr, thresholds = roc_curve(y_predicted, y_actual)\n",
    "    #roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    #plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    \n",
    "    add_plot(plt, svm_rbf_public, 'darkorange', 'SVM-RBF-DATASET1')\n",
    "    add_plot(plt, svm_linear_public, 'blue', 'SVM-LINEAR-DATASET1')\n",
    "    add_plot(plt, svm_rbf_cha1, 'green', 'SVM-RBF-DATASET2')\n",
    "    add_plot(plt, svm_linear_cha1, 'magenta', 'SVM-LINEAR-DATASET2')\n",
    "    add_plot(plt, svm_rbf_cha2, 'pink', 'SVM-RBF-DATASET3')\n",
    "    add_plot(plt, svm_linear_cha2, 'brown', 'SVM-LINEAR-DATASET3')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    \n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_keras_model(model, show_shapes=True, show_layer_names=True):\n",
    "    model_svg = model_to_dot(model, show_shapes=show_shapes, show_layer_names=show_layer_names).create(prog='dot',format='svg')\n",
    "    display(SVG(model_svg))\n",
    "    \n",
    "def draw_bar_chart(accuracies):\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    \n",
    "    min_y = min(accuracies.values()) - 20\n",
    "    \n",
    "    objects = accuracies.keys()\n",
    "    y_pos = numpy.arange(len(accuracies.keys()))\n",
    "    performance = accuracies.values()\n",
    "    \n",
    "    plt.ylim([min_y, 100])\n",
    "    plt.margins(x=.01)\n",
    "\n",
    "    plt.bar(y_pos, performance, align='center', color='green', width=0.6)\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('No. of Samples')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learning algorithm related\n",
    "\n",
    "# Feed forward\n",
    "def run_feed_forward(data, do_plot=False, show_progress=True):\n",
    "    \n",
    "    INPUT_DIMENSION = len(data[0]) - 1\n",
    "    LAYER_1_DIMENSION = 300\n",
    "    LAYER_2_DIMENSION = 300\n",
    "    OUTPUT_DIMENSION = 1\n",
    "    EPOCH = 100\n",
    "    \n",
    "    train_len = int(len(data) * .7)\n",
    "    data_train = data[0:train_len]\n",
    "    data_test = data[train_len:]\n",
    "\n",
    "    num_col = len(data_train[0]) - 1\n",
    "\n",
    "    x_train = data_train[:, 0:num_col]\n",
    "    y_train = data_train[:, num_col:].flatten()\n",
    "\n",
    "    x_test = data_test[:, 0:num_col]\n",
    "    y_test = data_test[:, num_col:].flatten()\n",
    "    \n",
    "    # Early stopping  \n",
    "    early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(LAYER_1_DIMENSION,\n",
    "                    input_dim=INPUT_DIMENSION,\n",
    "                    activation='relu'))\n",
    "    # With regularizers\n",
    "    #model.add(Dense(LAYER_1_DIMENSION,\n",
    "    #                input_dim=INPUT_DIMENSION,\n",
    "    #                activation='relu',\n",
    "    #                kernel_regularizer=regularizers.l2(0.01),\n",
    "    #                activity_regularizer=regularizers.l1(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(LAYER_2_DIMENSION,\n",
    "                    activation='relu'))\n",
    "    # With regularizers\n",
    "    #model.add(Dense(LAYER_2_DIMENSION,\n",
    "    #                activation='relu',\n",
    "    #                kernel_regularizer=regularizers.l2(0.01),\n",
    "    #                activity_regularizer=regularizers.l1(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(OUTPUT_DIMENSION, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(x_train,\n",
    "                        y_train,\n",
    "                        epochs=EPOCH,\n",
    "                        batch_size=64,\n",
    "                        validation_split=0.15,\n",
    "                        callbacks=[early_stop],\n",
    "                        verbose=(1 if show_progress else 0))\n",
    "    \n",
    "    score = model.evaluate(x_test, y_test, batch_size=64)\n",
    "    \n",
    "    if do_plot:\n",
    "        print (score)\n",
    "        plot_keras_model(model)\n",
    "        draw_accuracy_and_loss(history)\n",
    "\n",
    "    return score\n",
    "\n",
    "# CNN\n",
    "def run_cnn(data, do_plot=False, show_progress=True):\n",
    "    EPOCH = 100\n",
    "    \n",
    "    train_len = int(len(data) * .7)\n",
    "    data_train = data[0:train_len]\n",
    "    data_test = data[train_len:]\n",
    "\n",
    "    num_col = len(data_train[0]) - 1\n",
    "\n",
    "    # Convert 1d array back to image for convolution\n",
    "    x_train_1D = data_train[:, 0:num_col]\n",
    "    x_train = numpy.array([z.reshape(INPUT_SHAPE) for z in x_train_1D])\n",
    "    y_train = data_train[:, num_col:].flatten()\n",
    "\n",
    "    # Convert 1d array back to image for convolution\n",
    "    x_test_1D = data_test[:, 0:num_col]\n",
    "    x_test = numpy.array([z.reshape(INPUT_SHAPE) for z in x_test_1D])\n",
    "    y_test = data_test[:, num_col:].flatten()\n",
    "    \n",
    "    # Early stopping  \n",
    "    early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=INPUT_SHAPE))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train,\n",
    "                        y_train,\n",
    "                        epochs=EPOCH,\n",
    "                        batch_size=64,\n",
    "                        validation_split=0.33,\n",
    "                        callbacks=[early_stop],\n",
    "                        verbose=(1 if show_progress else 0))\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, batch_size=64)\n",
    "    \n",
    "    if do_plot:\n",
    "        print (score)\n",
    "        plot_keras_model(model)\n",
    "        draw_accuracy_and_loss(history)\n",
    "        \n",
    "    return score\n",
    "\n",
    "# Svm\n",
    "def run_svm(data, do_plot=False):\n",
    "    \n",
    "    train_len = int(len(data) * .7)\n",
    "    data_train = data[0:train_len]\n",
    "    data_test = data[train_len:]\n",
    "    \n",
    "    num_col = len(data_train[0]) - 1\n",
    "    \n",
    "    x_train = data_train[:, 0:num_col]\n",
    "    y_train = data_train[:, num_col:].flatten()\n",
    "    \n",
    "    x_test = data_test[:, 0:num_col]\n",
    "    y_test = data_test[:, num_col:].flatten()\n",
    "    \n",
    "    clf = SVC(C=1.0, kernel='rbf')\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predicted = clf.predict(x_test)\n",
    "    score = clf.score(x_test, y_test) \n",
    "    \n",
    "    if do_plot:\n",
    "        print (score)\n",
    "        draw_roc(y_predicted, y_test)\n",
    "    \n",
    "    return score\n",
    "\n",
    "def run_svm_all(data, kernel='rbf'):\n",
    "    train_len = int(len(data) * .7)\n",
    "    data_train = data[0:train_len]\n",
    "    data_test = data[train_len:]\n",
    "    \n",
    "    num_col = len(data_train[0]) - 1\n",
    "    \n",
    "    x_train = data_train[:, 0:num_col]\n",
    "    y_train = data_train[:, num_col:].flatten()\n",
    "    \n",
    "    x_test = data_test[:, 0:num_col]\n",
    "    y_test = data_test[:, num_col:].flatten()\n",
    "    \n",
    "    clf = SVC(C=1.0, kernel=kernel)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predicted = clf.predict(x_test)\n",
    "    \n",
    "    return (y_predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs a particular algorithm with a dataset\n",
    "\n",
    "# Returns an array conaining 10, 20, .. 90, 100, 200, ..., len(data)\n",
    "def find_iterations(data):\n",
    "    total = len(data)\n",
    "    start = 10\n",
    "    iters = []\n",
    "    while start < total:\n",
    "        iters.append(start)\n",
    "        if start < 100:\n",
    "            start += 10\n",
    "        else:\n",
    "            start += 100\n",
    "    iters.append(total)\n",
    "    return iters\n",
    "\n",
    "def run_algorithm(algo_type, data_input, num_iter, handle_cold_start, label):\n",
    "    \n",
    "    if algo_type != 'svm' and algo_type != 'ffnn' and algo_type != 'cnn':\n",
    "        raise Exception('Algo type should be either svm or ffnn or cnn')\n",
    "        \n",
    "    print ('===========')\n",
    "    print (label)\n",
    "    print ('===========')\n",
    "    \n",
    "    # This fixes how many rows to consider for each run\n",
    "    num_data_rows = find_iterations(data_input) if handle_cold_start else [len(data_input)]\n",
    "    \n",
    "    # Holds results\n",
    "    accuracies = dict()\n",
    "    \n",
    "    data_cache = numpy.copy(data_input)\n",
    "    \n",
    "    for cur_rows in num_data_rows:\n",
    "        sum = 0\n",
    "        for i in range(0, num_iter):\n",
    "            # First get the desired number of rows\n",
    "            numpy.random.shuffle(data_input)\n",
    "            data = data_input[0:cur_rows]\n",
    "            \n",
    "            if algo_type == 'svm':\n",
    "                sum += run_svm(data, False)\n",
    "            elif algo_type == 'ffnn':    \n",
    "                sum += run_feed_forward(data=data, do_plot=False, show_progress=False)[1]\n",
    "            else: # cnn\n",
    "                sum += run_cnn(data, False, show_progress=False)[1]\n",
    "        sum /= num_iter\n",
    "        print (cur_rows, sum)\n",
    "        accuracies[cur_rows] = round(sum*100)\n",
    "        \n",
    "    print ('accuracies for', label, ':', accuracies)\n",
    "    draw_bar_chart(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata = get_feature_with_labels(ham_dir=\"NaturalImages\", spam_dir=\"SpamImages\")\\nsvm_rbf_public = run_svm_all(data, \\'rbf\\')\\nsvm_linear_public = run_svm_all(data, \\'linear\\')\\n\\ndata = get_feature_with_labels(ham_dir=\"ChallengeHam1\", spam_dir=\"ChallengeSpam1\")\\nsvm_rbf_cha1 = run_svm_all(data, \\'rbf\\')\\nsvm_linear_cha1 = run_svm_all(data, \\'linear\\')\\n\\ndata = get_feature_with_labels(ham_dir=\"ChallengeHam2\", spam_dir=\"ChallengeSpam2\")\\nsvm_rbf_cha2 = run_svm_all(data, \\'rbf\\')\\nsvm_linear_cha2 = run_svm_all(data, \\'linear\\')\\n\\ndraw_roc_for_all(svm_rbf_public,svm_linear_public, svm_rbf_cha1,svm_linear_cha1, svm_rbf_cha2, svm_linear_cha2)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draws ROC for all SVM\n",
    "\"\"\"\n",
    "data = get_feature_with_labels(ham_dir=\"NaturalImages\", spam_dir=\"SpamImages\")\n",
    "svm_rbf_public = run_svm_all(data, 'rbf')\n",
    "svm_linear_public = run_svm_all(data, 'linear')\n",
    "\n",
    "data = get_feature_with_labels(ham_dir=\"ChallengeHam1\", spam_dir=\"ChallengeSpam1\")\n",
    "svm_rbf_cha1 = run_svm_all(data, 'rbf')\n",
    "svm_linear_cha1 = run_svm_all(data, 'linear')\n",
    "\n",
    "data = get_feature_with_labels(ham_dir=\"ChallengeHam2\", spam_dir=\"ChallengeSpam2\")\n",
    "svm_rbf_cha2 = run_svm_all(data, 'rbf')\n",
    "svm_linear_cha2 = run_svm_all(data, 'linear')\n",
    "\n",
    "draw_roc_for_all(svm_rbf_public,svm_linear_public, svm_rbf_cha1,svm_linear_cha1, svm_rbf_cha2, svm_linear_cha2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done generating data\n"
     ]
    }
   ],
   "source": [
    "# For testing, uncomment and save data to reuse\n",
    "\n",
    "data_public = get_feature_with_labels(\n",
    "    ham_dir=\"NaturalImages\",\n",
    "    spam_dir=\"SpamImages\",\n",
    "    show=False,\n",
    "    use_raw_images=USE_RAW_IMAGE_FEATURES,\n",
    "    use_canny_images=USE_CANNY_IMAGE_FEATURES\n",
    ")\n",
    "\n",
    "data_ds1 = get_feature_with_labels(\n",
    "    ham_dir=\"ChallengeHam1\",\n",
    "    spam_dir=\"ChallengeSpam1\",\n",
    "    show=False,\n",
    "    use_raw_images=USE_RAW_IMAGE_FEATURES,\n",
    "    use_canny_images=USE_CANNY_IMAGE_FEATURES\n",
    ")\n",
    "\n",
    "data_ds2 = get_feature_with_labels(\n",
    "    ham_dir=\"ChallengeHam2\",\n",
    "    spam_dir=\"ChallengeSpam2\",\n",
    "    show=False,\n",
    "    use_raw_images=USE_RAW_IMAGE_FEATURES,\n",
    "    use_canny_images=USE_CANNY_IMAGE_FEATURES\n",
    ")\n",
    "\n",
    "print ('Done generating data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      "cnn_ds1\n",
      "===========\n",
      "Epoch 00027: early stopping\n",
      "486/486 [==============================] - 0s 829us/step\n",
      "Epoch 00019: early stopping\n",
      "486/486 [==============================] - 0s 752us/step\n",
      "Epoch 00028: early stopping\n",
      "486/486 [==============================] - 0s 819us/step\n",
      "Epoch 00017: early stopping\n",
      "486/486 [==============================] - 0s 829us/step\n",
      "Epoch 00016: early stopping\n",
      "486/486 [==============================] - 0s 731us/step\n",
      "1620 0.8069958842830893\n",
      "accuracies for cnn_ds1 : {1620: 81.0}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      "cnn_ds2\n",
      "===========\n",
      "Epoch 00020: early stopping\n",
      "486/486 [==============================] - 0s 712us/step\n",
      "Epoch 00018: early stopping\n",
      "486/486 [==============================] - 0s 745us/step\n",
      "Epoch 00016: early stopping\n",
      "486/486 [==============================] - 0s 742us/step\n",
      "Epoch 00017: early stopping\n",
      "486/486 [==============================] - 0s 779us/step\n",
      "Epoch 00023: early stopping\n",
      "486/486 [==============================] - 0s 703us/step\n",
      "1620 0.6485596706837784\n",
      "accuracies for cnn_ds2 : {1620: 65.0}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      "cnn_public\n",
      "===========\n",
      "Epoch 00040: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Epoch 00008: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Epoch 00022: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Epoch 00006: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Epoch 00012: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "10 1.0\n",
      "Epoch 00012: early stopping\n",
      "6/6 [==============================] - 0s 926us/step\n",
      "Epoch 00020: early stopping\n",
      "6/6 [==============================] - 0s 906us/step\n",
      "Epoch 00015: early stopping\n",
      "6/6 [==============================] - 0s 876us/step\n",
      "Epoch 00032: early stopping\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Epoch 00016: early stopping\n",
      "6/6 [==============================] - 0s 878us/step\n",
      "20 0.8666666626930237\n",
      "Epoch 00030: early stopping\n",
      "9/9 [==============================] - 0s 814us/step\n",
      "Epoch 00071: early stopping\n",
      "9/9 [==============================] - 0s 881us/step\n",
      "Epoch 00025: early stopping\n",
      "9/9 [==============================] - 0s 851us/step\n",
      "Epoch 00023: early stopping\n",
      "9/9 [==============================] - 0s 821us/step\n",
      "Epoch 00028: early stopping\n",
      "9/9 [==============================] - 0s 920us/step\n",
      "30 0.711111119389534\n",
      "Epoch 00032: early stopping\n",
      "12/12 [==============================] - 0s 895us/step\n",
      "Epoch 00018: early stopping\n",
      "12/12 [==============================] - 0s 942us/step\n",
      "Epoch 00032: early stopping\n",
      "12/12 [==============================] - 0s 864us/step\n",
      "Epoch 00017: early stopping\n",
      "12/12 [==============================] - 0s 871us/step\n",
      "Epoch 00062: early stopping\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "40 0.8333333373069763\n",
      "Epoch 00014: early stopping\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "Epoch 00022: early stopping\n",
      "15/15 [==============================] - 0s 900us/step\n",
      "Epoch 00027: early stopping\n",
      "15/15 [==============================] - 0s 770us/step\n",
      "Epoch 00019: early stopping\n",
      "15/15 [==============================] - 0s 775us/step\n",
      "Epoch 00027: early stopping\n",
      "15/15 [==============================] - 0s 862us/step\n",
      "50 0.7866666793823243\n",
      "Epoch 00020: early stopping\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "Epoch 00029: early stopping\n",
      "18/18 [==============================] - 0s 983us/step\n",
      "Epoch 00044: early stopping\n",
      "18/18 [==============================] - 0s 858us/step\n",
      "Epoch 00031: early stopping\n",
      "18/18 [==============================] - 0s 763us/step\n",
      "Epoch 00018: early stopping\n",
      "18/18 [==============================] - 0s 773us/step\n",
      "60 0.7555555582046509\n",
      "Epoch 00013: early stopping\n",
      "21/21 [==============================] - 0s 959us/step\n",
      "Epoch 00023: early stopping\n",
      "21/21 [==============================] - 0s 795us/step\n",
      "Epoch 00018: early stopping\n",
      "21/21 [==============================] - 0s 760us/step\n",
      "Epoch 00015: early stopping\n",
      "21/21 [==============================] - 0s 814us/step\n",
      "Epoch 00022: early stopping\n",
      "21/21 [==============================] - 0s 854us/step\n",
      "70 0.9238095283508301\n",
      "Epoch 00032: early stopping\n",
      "24/24 [==============================] - 0s 795us/step\n",
      "Epoch 00024: early stopping\n",
      "24/24 [==============================] - 0s 734us/step\n",
      "Epoch 00027: early stopping\n",
      "24/24 [==============================] - 0s 877us/step\n",
      "Epoch 00025: early stopping\n",
      "24/24 [==============================] - 0s 938us/step\n",
      "Epoch 00036: early stopping\n",
      "24/24 [==============================] - 0s 803us/step\n",
      "80 0.875\n",
      "Epoch 00041: early stopping\n",
      "28/28 [==============================] - 0s 788us/step\n",
      "Epoch 00011: early stopping\n",
      "28/28 [==============================] - 0s 844us/step\n",
      "Epoch 00045: early stopping\n",
      "28/28 [==============================] - 0s 971us/step\n",
      "Epoch 00024: early stopping\n",
      "28/28 [==============================] - 0s 846us/step\n",
      "Epoch 00020: early stopping\n",
      "28/28 [==============================] - 0s 903us/step\n",
      "90 0.9285714268684387\n",
      "Epoch 00030: early stopping\n",
      "30/30 [==============================] - 0s 759us/step\n",
      "Epoch 00029: early stopping\n",
      "30/30 [==============================] - 0s 710us/step\n",
      "Epoch 00051: early stopping\n",
      "30/30 [==============================] - 0s 724us/step\n",
      "Epoch 00018: early stopping\n",
      "30/30 [==============================] - 0s 992us/step\n",
      "Epoch 00023: early stopping\n",
      "30/30 [==============================] - 0s 740us/step\n",
      "100 0.8799999952316284\n",
      "Epoch 00044: early stopping\n",
      "60/60 [==============================] - 0s 699us/step\n",
      "Epoch 00023: early stopping\n",
      "60/60 [==============================] - 0s 661us/step\n",
      "Epoch 00041: early stopping\n",
      "60/60 [==============================] - 0s 676us/step\n",
      "Epoch 00025: early stopping\n",
      "60/60 [==============================] - 0s 781us/step\n",
      "Epoch 00014: early stopping\n",
      "60/60 [==============================] - 0s 628us/step\n",
      "200 0.9233333349227906\n",
      "Epoch 00019: early stopping\n",
      "90/90 [==============================] - 0s 966us/step\n",
      "Epoch 00041: early stopping\n",
      "90/90 [==============================] - 0s 892us/step\n",
      "Epoch 00024: early stopping\n",
      "90/90 [==============================] - 0s 752us/step\n",
      "Epoch 00023: early stopping\n",
      "90/90 [==============================] - 0s 1ms/step\n",
      "Epoch 00027: early stopping\n",
      "90/90 [==============================] - 0s 1ms/step\n",
      "300 0.926666660838657\n",
      "Epoch 00031: early stopping\n",
      "120/120 [==============================] - 0s 857us/step\n",
      "Epoch 00017: early stopping\n",
      "120/120 [==============================] - 0s 707us/step\n",
      "Epoch 00025: early stopping\n",
      "120/120 [==============================] - 0s 746us/step\n",
      "Epoch 00025: early stopping\n",
      "120/120 [==============================] - 0s 738us/step\n",
      "Epoch 00027: early stopping\n",
      "120/120 [==============================] - 0s 711us/step\n",
      "400 0.956666669845581\n",
      "Epoch 00043: early stopping\n",
      "150/150 [==============================] - 0s 886us/step\n",
      "Epoch 00040: early stopping\n",
      "150/150 [==============================] - 0s 780us/step\n",
      "Epoch 00056: early stopping\n",
      "150/150 [==============================] - 0s 813us/step\n",
      "Epoch 00026: early stopping\n",
      "150/150 [==============================] - 0s 880us/step\n",
      "Epoch 00012: early stopping\n",
      "150/150 [==============================] - 0s 770us/step\n",
      "500 0.942666666348775\n",
      "Epoch 00019: early stopping\n",
      "180/180 [==============================] - 0s 1ms/step\n",
      "Epoch 00023: early stopping\n",
      "180/180 [==============================] - 0s 995us/step\n",
      "Epoch 00033: early stopping\n",
      "180/180 [==============================] - 0s 857us/step\n",
      "Epoch 00040: early stopping\n",
      "180/180 [==============================] - 0s 927us/step\n",
      "Epoch 00039: early stopping\n",
      "180/180 [==============================] - 0s 853us/step\n",
      "600 0.9533333349227904\n",
      "Epoch 00017: early stopping\n",
      "211/211 [==============================] - 0s 1ms/step\n",
      "Epoch 00032: early stopping\n",
      "211/211 [==============================] - 0s 927us/step\n",
      "Epoch 00027: early stopping\n",
      "211/211 [==============================] - 0s 983us/step\n",
      "Epoch 00010: early stopping\n",
      "211/211 [==============================] - 0s 964us/step\n",
      "Epoch 00043: early stopping\n",
      "211/211 [==============================] - 0s 965us/step\n",
      "700 0.7781990534886365\n",
      "Epoch 00018: early stopping\n",
      "240/240 [==============================] - 0s 814us/step\n",
      "Epoch 00033: early stopping\n",
      "240/240 [==============================] - 0s 994us/step\n",
      "Epoch 00031: early stopping\n",
      "240/240 [==============================] - 0s 934us/step\n",
      "Epoch 00025: early stopping\n",
      "240/240 [==============================] - 0s 990us/step\n",
      "Epoch 00034: early stopping\n",
      "240/240 [==============================] - 0s 987us/step\n",
      "800 0.9408333341280619\n",
      "Epoch 00021: early stopping\n",
      "270/270 [==============================] - 0s 922us/step\n",
      "Epoch 00023: early stopping\n",
      "270/270 [==============================] - 0s 934us/step\n",
      "Epoch 00015: early stopping\n",
      "270/270 [==============================] - 0s 962us/step\n",
      "Epoch 00032: early stopping\n",
      "270/270 [==============================] - 0s 861us/step\n",
      "Epoch 00018: early stopping\n",
      "270/270 [==============================] - 0s 1ms/step\n",
      "900 0.9503703701054608\n",
      "Epoch 00024: early stopping\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Epoch 00018: early stopping\n",
      "300/300 [==============================] - 0s 853us/step\n",
      "Epoch 00020: early stopping\n",
      "300/300 [==============================] - 0s 898us/step\n",
      "Epoch 00033: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 898us/step\n",
      "Epoch 00025: early stopping\n",
      "300/300 [==============================] - 0s 928us/step\n",
      "1000 0.8820000012715656\n",
      "Epoch 00018: early stopping\n",
      "330/330 [==============================] - 0s 873us/step\n",
      "Epoch 00023: early stopping\n",
      "330/330 [==============================] - 0s 844us/step\n",
      "Epoch 00022: early stopping\n",
      "330/330 [==============================] - 0s 976us/step\n",
      "Epoch 00037: early stopping\n",
      "330/330 [==============================] - 0s 884us/step\n",
      "Epoch 00032: early stopping\n",
      "330/330 [==============================] - 0s 1ms/step\n",
      "1100 0.9684848484126004\n",
      "Epoch 00024: early stopping\n",
      "360/360 [==============================] - 0s 969us/step\n",
      "Epoch 00035: early stopping\n",
      "360/360 [==============================] - 0s 972us/step\n",
      "Epoch 00034: early stopping\n",
      "360/360 [==============================] - 0s 923us/step\n",
      "Epoch 00014: early stopping\n",
      "360/360 [==============================] - 0s 1ms/step\n",
      "Epoch 00044: early stopping\n",
      "360/360 [==============================] - 0s 933us/step\n",
      "1200 0.9561111119058398\n",
      "Epoch 00039: early stopping\n",
      "391/391 [==============================] - 0s 847us/step\n",
      "Epoch 00029: early stopping\n",
      "391/391 [==============================] - 0s 879us/step\n"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "\n",
    "def main():\n",
    "    \n",
    "    NUM_ITERATIONS_PER_SET = 5\n",
    "    \n",
    "    run_algorithm('svm', data_ds1, num_iter=NUM_ITERATIONS_PER_SET, handle_cold_start=False, label='svm_ds1')\n",
    "    run_algorithm('svm', data_ds2, num_iter=NUM_ITERATIONS_PER_SET, handle_cold_start=False, label='svm_ds2')\n",
    "    run_algorithm('svm', data_public, num_iter=NUM_ITERATIONS_PER_SET, handle_cold_start=True, label='svm_public')\n",
    "    \n",
    "    run_algorithm('ffnn', data_ds1, num_iter=NUM_ITERATIONS_PER_SET, handle_cold_start=False, label='ffnn_ds1')\n",
    "    run_algorithm('ffnn', data_ds2, num_iter=NUM_ITERATIONS_PER_SET, handle_cold_start=False, label='ffnn_ds2')\n",
    "    run_algorithm('ffnn', data_public, num_iter=NUM_ITERATIONS_PER_SET, handle_cold_start=True, label='ffnn_public')\n",
    "    \n",
    "    run_algorithm('cnn', data_ds1, num_iter=NUM_ITERATIONS_PER_SET, handle_cold_start=False, label='cnn_ds1')\n",
    "    run_algorithm('cnn', data_ds2, num_iter=NUM_ITERATIONS_PER_SET, handle_cold_start=False, label='cnn_ds2')\n",
    "    run_algorithm('cnn', data_public, num_iter=NUM_ITERATIONS_PER_SET, handle_cold_start=True, label='cnn_public')\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section and rest are just tests\n",
    "def extract_features(imagePath, vector_size=32):\n",
    "    image = imageio.imread(imagePath)\n",
    "    alg = cv2.KAZE_create()\n",
    "    kps = alg.detect(image)\n",
    "    kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "    print (len(kps))\n",
    "    kps, dsc = alg.compute(image, kps)\n",
    "    print (len(dsc))\n",
    "    print (len(dsc[0]))\n",
    "    dsc = dsc.flatten()\n",
    "    print (len(dsc))\n",
    "    needed_size = (vector_size * 32)\n",
    "    if dsc.size < needed_size:\n",
    "        dsc = numpy.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "    return dsc\n",
    "\n",
    "def main2():\n",
    "    #features = create_feature_vector(\"SpamImages\", \"fire.jpg\")\n",
    "    #print len(features)\n",
    "    #print features\n",
    "    #image = cv2.imread(\"SpamImages/fire.jpg\")\n",
    "    #plotImage(image)\n",
    "    #image2 = cv2.resize(image, (600, 600))\n",
    "    #plotImage(image2)\n",
    "    \n",
    "    \n",
    "    \"\"\"data = get_feature_with_labels()\n",
    "    data\"\"\"\n",
    "    \n",
    "    #print (len(data[0]))\n",
    "    \n",
    "    \n",
    "\n",
    "    #create_feature_vector_for_canny(\"NaturalImages\", origImageName)\n",
    "    \n",
    "    #plainImageFileName = \"SpamImages/boots1.jpg\"\n",
    "    \"\"\"plainImage =  cv2.imread(plainImageFileName)\n",
    "    shape_hog(plainImage, \"HOG-Ham.png\")\n",
    "    \n",
    "    #plt.imshow(plainImage, cmap = 'gray', interpolation = 'bicubic')\n",
    "    #plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "    #plt.show()\n",
    "    cv_rgb = cv2.cvtColor(plainImage, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(cv_rgb)\n",
    "    plt.show()\n",
    "    \n",
    "    plainImage2 =  cv2.imread(\"HOG-Ham.png\")\n",
    "\n",
    "    print \"hi\"\n",
    "    \n",
    "    cv_rgb2 = cv2.cvtColor(plainImage2, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(cv_rgb2)\n",
    "    plt.show()\n",
    "\n",
    "    shape_cannyEdges(plainImage)\n",
    "    cv_rgb2 = cv2.cvtColor(cv2.imread(\"Cannyedges.jpg\"), cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(cv_rgb2)\n",
    "    plt.show()\"\"\"\n",
    "    \n",
    "    #x = create_feature_vector_for_canny(\"SpamImages\", \"fire.jpg\", 3.0)\n",
    "    numpy.set_printoptions(threshold=100)\n",
    "    #print x\n",
    "    \n",
    "    x = numpy.ndarray((10, 3))\n",
    "    print(x)\n",
    "    train_len = int(len(x) * .7)\n",
    "    #print x[0:train_len]\n",
    "    #print \"sep\"\n",
    "    #print x[train_len:]\n",
    "    \n",
    "    num_col = len(x[0]) - 1\n",
    "    \n",
    "    print(x[:,0:num_col])\n",
    "    \n",
    "    print(x[:, num_col:].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
