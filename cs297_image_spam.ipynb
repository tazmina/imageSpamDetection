{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import glob, os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import sys\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "from skimage import feature\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from IPython.display import SVG, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Constants\n",
    "IMG_WIDTH = 32\n",
    "IMG_HEIGHT = 32\n",
    "\n",
    "USE_RAW_IMAGE_FEATURES = True\n",
    "USE_CANNY_IMAGE_FEATURES = True\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    INPUT_SHAPE = (3, IMG_WIDTH * 2, IMG_HEIGHT)\n",
    "else:\n",
    "    INPUT_SHAPE = (IMG_WIDTH * 2, IMG_HEIGHT, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All image processing and plot related\n",
    "\n",
    "def plotImage(image):\n",
    "    cv_rgb2 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(cv_rgb2)\n",
    "    plt.show()\n",
    "\n",
    "def plotImageFromPath(imagePath):\n",
    "    plotImage(cv2.imread(imagePath))\n",
    "\n",
    "def shape_cannyEdgesOld(cv2Image, cannyImagePath):\n",
    "    v = numpy.median(cv2Image)\n",
    "    sigma = 0.0\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    #print \"Lower\", lower, \"Upper\", upper\n",
    "    grayScaleImage = cv2.cvtColor(cv2Image, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(grayScaleImage, 10, 255)\n",
    "    cv2.imshow('Canny edges',edges)\n",
    "    cv2.imwrite(cannyImagePath, edges)\n",
    "\n",
    "def shape_cannyEdges(cv2Image, cannyImagePath):\n",
    "    cv2Image[0,0] = (255, 0, 0)\n",
    "    cv2Image[0,1] = (0, 255, 0)\n",
    "    cv2Image[0,2] = (0, 0, 255)\n",
    "    \n",
    "    v = numpy.median(cv2Image)\n",
    "    sigma = 0.0\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    #print \"Lower\", lower, \"Upper\", upper\n",
    "    grayScaleImage = cv2.cvtColor(cv2Image, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(grayScaleImage, 10, 255)\n",
    "    cv2.imshow('Canny edges',edges)\n",
    "    cv2.imwrite(cannyImagePath, edges)\n",
    "    \n",
    "def shape_hog(cv2Image, fileName): \n",
    "    grayScaleImage = cv2.cvtColor(cv2Image, cv2.COLOR_BGR2GRAY)\n",
    "    fd, hog_image = feature.hog(grayScaleImage, orientations=8, pixels_per_cell=(16, 16),cells_per_block=(1, 1), visualise=True)\n",
    "    \n",
    "    cv2.imshow('HOG',hog_image)\n",
    "    cv2.imwrite(fileName, hog_image)\n",
    "    \n",
    "def create_canny_edge_image(origImageDir, origImageName):\n",
    "    \n",
    "    origImagePath = origImageDir + '/' + origImageName\n",
    "    print(origImagePath)\n",
    "    \n",
    "    cannyImageName = \"canny_\" + origImageName\n",
    "    cannyImagePath = origImageDir + '/' + cannyImageName\n",
    "    plainImage = cv2.imread(origImagePath)\n",
    "    shape_cannyEdges(plainImage, cannyImagePath)\n",
    "    \n",
    "    return cannyImagePath\n",
    "    \n",
    "def create_canny_for_all_img(origImageDir):\n",
    "    imgFiles = [filename for filename in os.listdir(origImageDir)\n",
    "                if (not filename.startswith(\"canny\") and filename.endswith(\".jpg\") )]\n",
    "    for origImageName in imgFiles:\n",
    "        cannyImageName = \"canny_\" + origImageName\n",
    "        cannyImagePath = origImageDir + '/' + cannyImageName\n",
    "        \n",
    "        if not os.path.exists(cannyImagePath):\n",
    "            create_canny_edge_image(origImageDir, origImageName)\n",
    "            \n",
    "def create_color_histogram (origImageDir, origImageName):\n",
    "    origImagePath = origImageDir + '/' + origImageName\n",
    "    plainImage = cv2.imread(origImagePath)\n",
    "    \n",
    "    hist = cv2.calcHist([plainImage], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    hist = hist.flatten()\n",
    "    print (hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All image feature verctor related\n",
    "\n",
    "def create_features_for_all_raw_img(origImageDir, isSpam):\n",
    "    imgFiles = [filename for filename in os.listdir(origImageDir)\n",
    "                if ((not filename.startswith(\"canny\")) and filename.endswith(\".jpg\") )]\n",
    "\n",
    "    res = [create_feature_vector(origImageDir, origImageName, isSpam) for origImageName in imgFiles]\n",
    "    return numpy.array(res)\n",
    "            \n",
    "def create_features_for_all_canny_img(origImageDir, isSpam):\n",
    "    imgFiles = [filename for filename in os.listdir(origImageDir)\n",
    "                if (filename.startswith(\"canny\") and filename.endswith(\".jpg\") )]\n",
    "    res = [create_feature_vector(origImageDir, origImageName, isSpam) for origImageName in imgFiles]\n",
    "    return numpy.array(res)\n",
    "    \n",
    "def create_feature_vector(origImageDir, origImageName, isSpam, numRow=IMG_HEIGHT, numCol=IMG_WIDTH):\n",
    "    origImagePath = origImageDir + '/' + origImageName\n",
    "    plainImage = cv2.imread(origImagePath)\n",
    "    resizedImage = cv2.resize(plainImage, (numRow, numCol))\n",
    "    h = resizedImage.shape[0]\n",
    "    w = resizedImage.shape[1]\n",
    "    res = numpy.ndarray(shape=(3, h, w), dtype=float, order='F')\n",
    "    # loop over the image, pixel by pixel\n",
    "    for y in range(0, h):\n",
    "        for x in range(0, w):\n",
    "            # threshold the pixel\n",
    "            color = resizedImage[y,x] \n",
    "            res[0, y, x] = color[0] / 255.0\n",
    "            res[1, y, x] = color[1] / 255.0\n",
    "            res[2, y, x] = color[2] / 255.0\n",
    "    return numpy.append(res.flatten(), isSpam)\n",
    "\n",
    "def crete_canny_and_get_features_with_labels(directory, label, use_raw_images, use_canny_images):\n",
    "    if (not use_raw_images) and (not use_canny_images):\n",
    "        raise Exception('At least use_raw_images or use_canny_images need to be set to true')\n",
    "        \n",
    "    create_canny_for_all_img(directory)\n",
    "    data_raw = create_features_for_all_raw_img(directory, label)\n",
    "    data_canny = create_features_for_all_canny_img(directory, label)\n",
    "    \n",
    "    if (use_raw_images and use_canny_images):\n",
    "        return numpy.column_stack((data_raw[:,:-1], data_canny))\n",
    "    elif use_raw_images:\n",
    "        return data_raw\n",
    "    else:\n",
    "        return data_canny\n",
    "\n",
    "def get_feature_with_labels(\n",
    "    ham_dir=\"NaturalImages\",\n",
    "    spam_dir=\"SpamImages\",\n",
    "    show=False,\n",
    "    use_raw_images=True,\n",
    "    use_canny_images=True\n",
    "):\n",
    "    data_ham = crete_canny_and_get_features_with_labels(\n",
    "        directory=ham_dir,\n",
    "        label=0,\n",
    "        use_raw_images=use_raw_images,\n",
    "        use_canny_images=use_canny_images\n",
    "    )\n",
    "    data_spam = crete_canny_and_get_features_with_labels(\n",
    "        directory=spam_dir,\n",
    "        label=1,\n",
    "        use_raw_images=use_raw_images,\n",
    "        use_canny_images=use_canny_images\n",
    "    )\n",
    "    \n",
    "    data = numpy.concatenate((data_ham, data_spam), axis=0)\n",
    "    numpy.random.shuffle(data)\n",
    "\n",
    "    if show:\n",
    "        #numpy.set_printoptions(threshold=sys.maxsize)\n",
    "        numpy.set_printoptions(threshold=10)\n",
    "        print(\"data_ham, using directory:\", ham_dir)\n",
    "        print(data_ham)\n",
    "        print(\"data_spam, using directory:\", spam_dir)\n",
    "        print(data_spam)\n",
    "        print(\"data\")\n",
    "        print(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot related\n",
    "def draw_accuracy_and_loss(history):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def draw_roc(y_predicted, y_actual):\n",
    "    fpr, tpr, thresholds = roc_curve(y_predicted, y_actual)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "def add_plot(plt, svm_res, color, label):\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(svm_res[0], svm_res[1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.plot(fpr, tpr, color=color, lw=1, label=(label + ' ROC curve (area = %0.2f)') % roc_auc)\n",
    "    \n",
    "    \n",
    "def draw_roc_for_all(svm_rbf_public, svm_linear_public, svm_rbf_cha1, svm_linear_cha1, svm_rbf_cha2, svm_linear_cha2):\n",
    "    plt.figure()\n",
    "    \n",
    "    #fpr, tpr, thresholds = roc_curve(y_predicted, y_actual)\n",
    "    #roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    #plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    \n",
    "    add_plot(plt, svm_rbf_public, 'darkorange', 'SVM-RBF-DATASET1')\n",
    "    add_plot(plt, svm_linear_public, 'blue', 'SVM-LINEAR-DATASET1')\n",
    "    add_plot(plt, svm_rbf_cha1, 'green', 'SVM-RBF-DATASET2')\n",
    "    add_plot(plt, svm_linear_cha1, 'magenta', 'SVM-LINEAR-DATASET2')\n",
    "    add_plot(plt, svm_rbf_cha2, 'pink', 'SVM-RBF-DATASET3')\n",
    "    add_plot(plt, svm_linear_cha2, 'brown', 'SVM-LINEAR-DATASET3')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    \n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_keras_model(model, show_shapes=True, show_layer_names=True):\n",
    "    model_svg = model_to_dot(model, show_shapes=show_shapes, show_layer_names=show_layer_names).create(prog='dot',format='svg')\n",
    "    display(SVG(model_svg))\n",
    "    \n",
    "def draw_bar_chart(accuracies):\n",
    "    plt.figure()\n",
    "    \n",
    "    objects = accuracies.keys()\n",
    "    y_pos = numpy.arange(len(accuracies.keys()))\n",
    "    performance = accuracies.values()\n",
    "\n",
    "    plt.bar(y_pos, performance, align='center')\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('No. of Samples')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learning algorithm related\n",
    "\n",
    "# Feed forward\n",
    "def run_feed_forward(data, do_plot=False):\n",
    "    \n",
    "    INPUT_DIMENSION = len(data[0]) - 1\n",
    "    LAYER_1_DIMENSION = 300\n",
    "    LAYER_2_DIMENSION = 300\n",
    "    OUTPUT_DIMENSION = 1\n",
    "    EPOCH = 100\n",
    "    \n",
    "    train_len = int(len(data) * .7)\n",
    "    data_train = data[0:train_len]\n",
    "    data_test = data[train_len:]\n",
    "\n",
    "    num_col = len(data_train[0]) - 1\n",
    "\n",
    "    x_train = data_train[:, 0:num_col]\n",
    "    y_train = data_train[:, num_col:].flatten()\n",
    "\n",
    "    x_test = data_test[:, 0:num_col]\n",
    "    y_test = data_test[:, num_col:].flatten()\n",
    "    \n",
    "    # Early stopping  \n",
    "    early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(LAYER_1_DIMENSION,\n",
    "                    input_dim=INPUT_DIMENSION,\n",
    "                    activation='relu'))\n",
    "    # With regularizers\n",
    "    #model.add(Dense(LAYER_1_DIMENSION,\n",
    "    #                input_dim=INPUT_DIMENSION,\n",
    "    #                activation='relu',\n",
    "    #                kernel_regularizer=regularizers.l2(0.01),\n",
    "    #                activity_regularizer=regularizers.l1(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(LAYER_2_DIMENSION,\n",
    "                    activation='relu'))\n",
    "    # With regularizers\n",
    "    #model.add(Dense(LAYER_2_DIMENSION,\n",
    "    #                activation='relu',\n",
    "    #                kernel_regularizer=regularizers.l2(0.01),\n",
    "    #                activity_regularizer=regularizers.l1(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(OUTPUT_DIMENSION, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(x_train,\n",
    "                        y_train,\n",
    "                        epochs=EPOCH,\n",
    "                        batch_size=64,\n",
    "                        validation_split=0.15,\n",
    "                        callbacks=[early_stop])\n",
    "    \n",
    "    score = model.evaluate(x_test, y_test, batch_size=64)\n",
    "    \n",
    "    if do_plot:\n",
    "        print (score)\n",
    "        plot_keras_model(model)\n",
    "        draw_accuracy_and_loss(history)\n",
    "\n",
    "    return score\n",
    "\n",
    "# CNN\n",
    "def run_cnn(data, do_plot=False):\n",
    "    EPOCH = 100\n",
    "    \n",
    "    train_len = int(len(data) * .7)\n",
    "    data_train = data[0:train_len]\n",
    "    data_test = data[train_len:]\n",
    "\n",
    "    num_col = len(data_train[0]) - 1\n",
    "\n",
    "    # Convert 1d array back to image for convolution\n",
    "    x_train_1D = data_train[:, 0:num_col]\n",
    "    x_train = numpy.array([z.reshape(INPUT_SHAPE) for z in x_train_1D])\n",
    "    y_train = data_train[:, num_col:].flatten()\n",
    "\n",
    "    # Convert 1d array back to image for convolution\n",
    "    x_test_1D = data_test[:, 0:num_col]\n",
    "    x_test = numpy.array([z.reshape(INPUT_SHAPE) for z in x_test_1D])\n",
    "    y_test = data_test[:, num_col:].flatten()\n",
    "    \n",
    "    # Early stopping  \n",
    "    early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=INPUT_SHAPE))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train,\n",
    "                        y_train,\n",
    "                        epochs=EPOCH,\n",
    "                        batch_size=64,\n",
    "                        validation_split=0.33,\n",
    "                        callbacks=[early_stop])\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, batch_size=64)\n",
    "    \n",
    "    if do_plot:\n",
    "        print (score)\n",
    "        plot_keras_model(model)\n",
    "        draw_accuracy_and_loss(history)\n",
    "        \n",
    "    return score\n",
    "\n",
    "# Svm\n",
    "def run_svm(data, do_plot=False):\n",
    "    \n",
    "    train_len = int(len(data) * .7)\n",
    "    data_train = data[0:train_len]\n",
    "    data_test = data[train_len:]\n",
    "    \n",
    "    num_col = len(data_train[0]) - 1\n",
    "    \n",
    "    x_train = data_train[:, 0:num_col]\n",
    "    y_train = data_train[:, num_col:].flatten()\n",
    "    \n",
    "    x_test = data_test[:, 0:num_col]\n",
    "    y_test = data_test[:, num_col:].flatten()\n",
    "    \n",
    "    clf = SVC(C=1.0, kernel='rbf')\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predicted = clf.predict(x_test)\n",
    "    score = clf.score(x_test, y_test) \n",
    "    \n",
    "    if do_plot:\n",
    "        print (score)\n",
    "        draw_roc(y_predicted, y_test)\n",
    "    \n",
    "    return score\n",
    "\n",
    "def run_svm_all(data, kernel='rbf'):\n",
    "    train_len = int(len(data) * .7)\n",
    "    data_train = data[0:train_len]\n",
    "    data_test = data[train_len:]\n",
    "    \n",
    "    num_col = len(data_train[0]) - 1\n",
    "    \n",
    "    x_train = data_train[:, 0:num_col]\n",
    "    y_train = data_train[:, num_col:].flatten()\n",
    "    \n",
    "    x_test = data_test[:, 0:num_col]\n",
    "    y_test = data_test[:, num_col:].flatten()\n",
    "    \n",
    "    clf = SVC(C=1.0, kernel=kernel)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_predicted = clf.predict(x_test)\n",
    "    \n",
    "    return (y_predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data = get_feature_with_labels(nonSpamDir=\"NaturalImages\", spamDir=\"SpamImages\")\\nsvm_rbf_public = run_svm_all(data, \\'rbf\\')\\nsvm_linear_public = run_svm_all(data, \\'linear\\')\\n\\ndata = get_feature_with_labels(nonSpamDir=\"ChallengeHam1\", spamDir=\"ChallengeSpam1\")\\nsvm_rbf_cha1 = run_svm_all(data, \\'rbf\\')\\nsvm_linear_cha1 = run_svm_all(data, \\'linear\\')\\n\\ndata = get_feature_with_labels(nonSpamDir=\"ChallengeHam2\", spamDir=\"ChallengeSpam2\")\\nsvm_rbf_cha2 = run_svm_all(data, \\'rbf\\')\\nsvm_linear_cha2 = run_svm_all(data, \\'linear\\')'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draws ROC for all SVM\n",
    "\"\"\"\n",
    "data = get_feature_with_labels(ham_dir=\"NaturalImages\", spam_dir=\"SpamImages\")\n",
    "svm_rbf_public = run_svm_all(data, 'rbf')\n",
    "svm_linear_public = run_svm_all(data, 'linear')\n",
    "\n",
    "data = get_feature_with_labels(ham_dir=\"ChallengeHam1\", spam_dir=\"ChallengeSpam1\")\n",
    "svm_rbf_cha1 = run_svm_all(data, 'rbf')\n",
    "svm_linear_cha1 = run_svm_all(data, 'linear')\n",
    "\n",
    "data = get_feature_with_labels(ham_dir=\"ChallengeHam2\", spam_dir=\"ChallengeSpam2\")\n",
    "svm_rbf_cha2 = run_svm_all(data, 'rbf')\n",
    "svm_linear_cha2 = run_svm_all(data, 'linear')\n",
    "\n",
    "draw_roc_for_all(svm_rbf_public,svm_linear_public, svm_rbf_cha1,svm_linear_cha1, svm_rbf_cha2, svm_linear_cha2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing, uncomment and save data to reuse\n",
    "\n",
    "data_public = get_feature_with_labels(\n",
    "    ham_dir=\"NaturalImages\",\n",
    "    spam_dir=\"SpamImages\",\n",
    "    show=False,\n",
    "    use_raw_images=USE_RAW_IMAGE_FEATURES,\n",
    "    use_canny_images=USE_CANNY_IMAGE_FEATURES\n",
    ")\n",
    "\n",
    "data_ds1 = get_feature_with_labels(\n",
    "    ham_dir=\"ChallengeHam1\",\n",
    "    spam_dir=\"ChallengeSpam1\",\n",
    "    show=False,\n",
    "    use_raw_images=USE_RAW_IMAGE_FEATURES,\n",
    "    use_canny_images=USE_CANNY_IMAGE_FEATURES\n",
    ")\n",
    "\n",
    "data_ds2 = get_feature_with_labels(\n",
    "    ham_dir=\"ChallengeHam2\",\n",
    "    spam_dir=\"ChallengeSpam2\",\n",
    "    show=False,\n",
    "    use_raw_images=USE_RAW_IMAGE_FEATURES,\n",
    "    use_canny_images=USE_CANNY_IMAGE_FEATURES\n",
    ")\n",
    "\n",
    "print ('Done generating data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs a particular algorithm with a dataset\n",
    "\n",
    "# Returns an array conaining 10, 20, .. 90, 100, 200, ..., len(data)\n",
    "def find_iterations(data):\n",
    "    total = len(data)\n",
    "    start = 10\n",
    "    iters = []\n",
    "    while start < total:\n",
    "        iters.append(start)\n",
    "        if start < 100:\n",
    "            start += 10\n",
    "        else:\n",
    "            start += 100\n",
    "    iters.append(total)\n",
    "    return iters\n",
    "\n",
    "def run_algorithm(algo_type, data_input, num_iter, handle_cold_start=True):\n",
    "    \n",
    "    if algo_type != 'svm' and algo_type != 'ffnn' and algo_type != 'cnn':\n",
    "        raise Exception('Algo type should be either svm or ffnn or cnn')\n",
    "    \n",
    "    # This fixes how many rows to consider for each run\n",
    "    num_data_rows = find_iterations(data_input) if handle_cold_start else [len(data_input)]\n",
    "    \n",
    "    # Holds results\n",
    "    accuracies = dict()\n",
    "    \n",
    "    data_cache = numpy.copy(data_input)\n",
    "    \n",
    "    for cur_rows in num_data_rows:\n",
    "        sum = 0\n",
    "        for i in range(0, num_iter):\n",
    "            # First get the desired number of rows\n",
    "            numpy.random.shuffle(data_cache)\n",
    "            data = data_cache[0:cur_rows]\n",
    "            \n",
    "            if algo_type == 'svm':\n",
    "                sum += run_svm(data, False)\n",
    "            elif algo_type == 'ffnn':    \n",
    "                sum += run_feed_forward(data, False)[1]\n",
    "            else: # cnn\n",
    "                sum += run_cnn(data, False)[1]\n",
    "        sum /= num_iter\n",
    "        print (cur_rows, sum)\n",
    "        accuracies[cur_rows] = round(sum*100)\n",
    "        \n",
    "    print ('accuracies: ', accuracies)\n",
    "    if handle_cold_start:\n",
    "        draw_bar_chart(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.4666666666666667\n",
      "20 0.8333333333333334\n",
      "30 0.9333333333333332\n",
      "40 0.9833333333333332\n",
      "50 0.9066666666666666\n",
      "60 0.9666666666666666\n",
      "70 0.980952380952381\n",
      "80 0.9166666666666666\n",
      "90 0.9642857142857142\n",
      "100 0.9333333333333332\n",
      "200 0.9433333333333331\n",
      "300 0.9533333333333334\n",
      "400 0.9400000000000001\n",
      "500 0.9560000000000001\n",
      "600 0.9466666666666667\n",
      "700 0.9336492890995262\n",
      "800 0.9583333333333333\n",
      "900 0.9392592592592592\n",
      "1000 0.9493333333333333\n",
      "1100 0.949090909090909\n",
      "1200 0.9538888888888888\n",
      "1300 0.9498721227621483\n",
      "1400 0.951543942992874\n",
      "1500 0.9488888888888889\n",
      "1600 0.9570833333333333\n"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "\n",
    "def main():\n",
    "    \n",
    "    NUM_ITERATIONS_PER_SET = 5\n",
    "    \n",
    "    run_algorithm('svm', data_public, num_iter=NUM_ITERATIONS_PER_SET, handle_cold_start=True)\n",
    "    #run_algorithm('svm', data_ds1, num_iter=NUM_ITERATIONS_PER_SET, handle_cold_start=True)\n",
    "    #run_algorithm('svm', data_ds2, num_iter=NUM_ITERATIONS_PER_SET, handle_cold_start=True)\n",
    "    \n",
    "    #run_algorithm('ffnn', data_public, num_iter=NUM_ITERATIONS_PER_SET, handle_cold_start=True)\n",
    "    #run_algorithm('ffnn', data_ds1, num_iter=NUM_ITERATIONS_PER_SET, handle_cold_start=True)\n",
    "    #run_algorithm('ffnn', data_ds2, num_iter=NUM_ITERATIONS_PER_SET, handle_cold_start=True)\n",
    "    \n",
    "    #run_algorithm('cnn', data_public, num_iter=NUM_ITERATIONS_PER_SET, handle_cold_start=True)\n",
    "    #run_algorithm('cnn', data_ds1, num_iter=NUM_ITERATIONS_PER_SET, handle_cold_start=True)\n",
    "    #run_algorithm('cnn', data_ds2, num_iter=NUM_ITERATIONS_PER_SET, handle_cold_start=True)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section and rest are just tests\n",
    "def extract_features(imagePath, vector_size=32):\n",
    "    image = imageio.imread(imagePath)\n",
    "    alg = cv2.KAZE_create()\n",
    "    kps = alg.detect(image)\n",
    "    kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "    print (len(kps))\n",
    "    kps, dsc = alg.compute(image, kps)\n",
    "    print (len(dsc))\n",
    "    print (len(dsc[0]))\n",
    "    dsc = dsc.flatten()\n",
    "    print (len(dsc))\n",
    "    needed_size = (vector_size * 32)\n",
    "    if dsc.size < needed_size:\n",
    "        dsc = numpy.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "    return dsc\n",
    "\n",
    "def main2():\n",
    "    #features = create_feature_vector(\"SpamImages\", \"fire.jpg\")\n",
    "    #print len(features)\n",
    "    #print features\n",
    "    #image = cv2.imread(\"SpamImages/fire.jpg\")\n",
    "    #plotImage(image)\n",
    "    #image2 = cv2.resize(image, (600, 600))\n",
    "    #plotImage(image2)\n",
    "    \n",
    "    \n",
    "    \"\"\"data = get_feature_with_labels()\n",
    "    data\"\"\"\n",
    "    \n",
    "    #print (len(data[0]))\n",
    "    \n",
    "    \n",
    "\n",
    "    #create_feature_vector_for_canny(\"NaturalImages\", origImageName)\n",
    "    \n",
    "    #plainImageFileName = \"SpamImages/boots1.jpg\"\n",
    "    \"\"\"plainImage =  cv2.imread(plainImageFileName)\n",
    "    shape_hog(plainImage, \"HOG-Ham.png\")\n",
    "    \n",
    "    #plt.imshow(plainImage, cmap = 'gray', interpolation = 'bicubic')\n",
    "    #plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "    #plt.show()\n",
    "    cv_rgb = cv2.cvtColor(plainImage, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(cv_rgb)\n",
    "    plt.show()\n",
    "    \n",
    "    plainImage2 =  cv2.imread(\"HOG-Ham.png\")\n",
    "\n",
    "    print \"hi\"\n",
    "    \n",
    "    cv_rgb2 = cv2.cvtColor(plainImage2, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(cv_rgb2)\n",
    "    plt.show()\n",
    "\n",
    "    shape_cannyEdges(plainImage)\n",
    "    cv_rgb2 = cv2.cvtColor(cv2.imread(\"Cannyedges.jpg\"), cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(cv_rgb2)\n",
    "    plt.show()\"\"\"\n",
    "    \n",
    "    #x = create_feature_vector_for_canny(\"SpamImages\", \"fire.jpg\", 3.0)\n",
    "    numpy.set_printoptions(threshold=100)\n",
    "    #print x\n",
    "    \n",
    "    x = numpy.ndarray((10, 3))\n",
    "    print(x)\n",
    "    train_len = int(len(x) * .7)\n",
    "    #print x[0:train_len]\n",
    "    #print \"sep\"\n",
    "    #print x[train_len:]\n",
    "    \n",
    "    num_col = len(x[0]) - 1\n",
    "    \n",
    "    print(x[:,0:num_col])\n",
    "    \n",
    "    print(x[:, num_col:].flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
